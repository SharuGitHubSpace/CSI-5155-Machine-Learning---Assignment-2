{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2df6dcf",
   "metadata": {},
   "source": [
    "\n",
    "# Saranya 300321456 - Assignment 2 - Evaluation of Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce77b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as bsns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from imblearn.pipeline import Pipeline, make_pipeline \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.feature_selection import SelectKBest , f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26fc0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    " \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05e5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "def category_to_number(X, to_one_hot = [], to_ordinal =[]):\n",
    "    '''\n",
    "    Input:  X - original dataset\n",
    "            to_one_hot - the columns that need to be One hot encoded\n",
    "            to_ordinal  - the columns that need to be oridinal encoded\n",
    "    \n",
    "    Output: X - after all the processing done\n",
    "    \n",
    "    Function to change the categorical variables present in the dataset to encoded numericals   \n",
    "    \n",
    "    '''\n",
    "    OHen = OneHotEncoder()\n",
    "    Oren = OrdinalEncoder()\n",
    "    n = X.shape[1]\n",
    "    # looping through the columns and encodering the categorical column     \n",
    "    for i in range(n):\n",
    "        \n",
    "        # One hot encoding for cardinal columns\n",
    "        if not to_one_hot:\n",
    "            if X.iloc[:,i].name in to_one_hot:\n",
    "                OHE = OHen.fit_transform(X.iloc[:,[i]])\n",
    "                df = pd.DataFrame(OHE.toarray(),columns=[X.iloc[:,i].name+\"_\"+y for y in X.iloc[:,i].unique()])\n",
    "                X = pd.merge(left=X,right=df,left_index=True,right_index=True)\n",
    "        \n",
    "        # Ordinal encoding for ordinal columns\n",
    "        if X.iloc[:,i].name in to_ordinal:\n",
    "            X.loc[:,X.iloc[:,i].name] = Oren.fit_transform(X.iloc[:,[i]])\n",
    "    \n",
    "    # Dropping the cardinal categorical columns to avoind redundancy  \n",
    "    X.drop(columns=to_one_hot,inplace = True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f6efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_selection(X,y):\n",
    "    noOfFeaturesSelected = 8\n",
    "    from sklearn.feature_selection import SelectKBest , f_classif\n",
    "    selector = SelectKBest(f_classif, k=noOfFeaturesSelected)\n",
    "    selector.fit(X,y) \n",
    "    selector.scores_\n",
    "\n",
    "    # Significant Features for Alcohol\n",
    "    cols = selector.get_support(indices=True)    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c691801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    DT__params = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [1, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              # \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    \n",
    "    SVC__params = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf','poly', 'sigmoid']} \n",
    "    \n",
    "    RF__params = { \n",
    "              'n_estimators': [200, 700],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']\n",
    "                }\n",
    "    k_range = list(range(1, 31))\n",
    "    KNN__Params = dict(n_neighbors=k_range)\n",
    "    \n",
    "    MLP__params = {\n",
    "            'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            'solver': ['sgd', 'adam'],\n",
    "            'alpha': [0.0001, 0.05],\n",
    "            'learning_rate': ['constant','adaptive'],\n",
    "                }\n",
    "    GB__params = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfb36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # define the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models = []\n",
    "models.append(('SVM',SVC__params,SVC(kernel='linear',random_state=4)))\n",
    "models.append(('DT',DT__params,DecisionTreeClassifier()))\n",
    "models.append(('RF',RF__params,RandomForestClassifier(n_estimators=40)))\n",
    "models.append(('KNN',KNN__Params,KNeighborsClassifier(n_neighbors=4)))\n",
    "models.append(('MLP',MLP__params,MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(256,128,64,32), activation=\"relu\", random_state=1)))\n",
    "models.append(('GB',GB__params,GradientBoostingClassifier(random_state=42)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69568a29",
   "metadata": {},
   "source": [
    "# VSA - Dataset with Highest prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd58d70",
   "metadata": {},
   "source": [
    "1) Load Data set\n",
    "2) Feature Scaling\n",
    "3) Feature Selecton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa6f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "def get_dataset():\n",
    "    # DF -- VSA\n",
    "    path = 'C:/Users/VaishuSistas/Desktop/ML/Assignments/Assignment1/Data/Assignment1_drug_consumption.txt'\n",
    "    dfmainVSA  = pd.read_csv(path,usecols=[1,2,3,4,5,6,7,8,9,10,11,12,31]) \n",
    "    dfmainVSA.columns = ['Age','Gender','Education','Country','Ethnicity',\n",
    "                         'NScore','Escore','OScore','AScore','CScore',\n",
    "                         'Impulse','SS','DrugClass'] \n",
    "    dfmainVSA['DrugClass'] = dfmainVSA ['DrugClass'].apply(lambda x: '0' if (x == 'CL1' or x == 'CL0') else '1')\n",
    "    dfmainVSA.head(20)\n",
    "    dfmainVSA.groupby('DrugClass').mean()\n",
    "\n",
    "    X = dfmainVSA[dfmainVSA.columns[~dfmainVSA.columns.isin(['DrugClass'])]]\n",
    "    y = dfmainVSA['DrugClass']\n",
    "    dfmainVSA.groupby(['DrugClass'])['DrugClass'].count()\n",
    "    # Feature Scaling - Drug DS\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = pd.DataFrame(scaler.transform(X)) \n",
    "    \n",
    "    # Feature selection\n",
    "    cols = Feature_selection(X,y)\n",
    "    X = X.iloc[:,cols]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c6b49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Labour negotiations dataset\n",
    "def Get_Labordataset():\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    labour_data_1 = pd.read_csv(\"LabourDataset/labor-neg.data\",na_values=\"?\")\n",
    "    labour_data_2 =pd.read_csv(\"LabourDataset/labor-neg.test\",na_values=\"?\")\n",
    "    labour_data = labour_data_1.append(labour_data_2, ignore_index = True)\n",
    "\n",
    "    # Features split and output class target variable\n",
    "    labour_X = labour_data.iloc[:,:-1]\n",
    "    labour_y = labour_data.iloc[:,-1]\n",
    "\n",
    "    # Checking missing values in dataset\n",
    "    #print((np.sum(labour_X.isnull(),axis=0)))\n",
    "\n",
    "    # Dropping columns with missing values more than 20\n",
    "    labour_X.dropna(axis=1,thresh=labour_X.shape[0] - 20,inplace=True)\n",
    "\n",
    "\n",
    "    # Imputing missing values in numerical columns\n",
    "    num_imputer=SimpleImputer(strategy=\"mean\")\n",
    "    labour_X.loc[:,labour_X.dtypes == \"float64\"] = num_imputer.fit_transform(labour_X.loc[:,labour_X.dtypes == \"float64\"])\n",
    "\n",
    "    # Imputing missing values in categorical columns\n",
    "    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    labour_X.loc[:,labour_X.dtypes == \"object\"] = cat_imputer.fit_transform(labour_X.loc[:,labour_X.dtypes == \"object\"])\n",
    "\n",
    "    # converting categorival variables to numerical variables\n",
    "    column_names=labour_X.loc[:,labour_X.dtypes == \"object\"].columns\n",
    "\n",
    "    labour_X = category_to_number(labour_X,to_ordinal=column_names)\n",
    "    \n",
    "    # Feature Scaling\n",
    "        \n",
    "    Scaler_1 = MinMaxScaler(feature_range=(0, 1)).fit(labour_X)\n",
    "    labour_X = pd.DataFrame(Scaler_1.transform(labour_X)) \n",
    "    \n",
    "    # Feature Selection\n",
    "     \n",
    "    cols = Feature_selection(labour_X,labour_y)\n",
    "    labour_X = labour_X.iloc[:,cols]\n",
    "        \n",
    "    return labour_X, labour_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f5a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Labour negotiations dataset\n",
    "def Get_HeartDataset():\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    # Importing Heart disease dataset\n",
    "    Heart_dataset = pd.read_csv(\"HeartDisease/heart_cleveland_upload.csv\",sep=\",\")\n",
    "    # Features split and output class target variable\n",
    "    heart_X = Heart_dataset.iloc[:,:-1]\n",
    "    heart_y = Heart_dataset.iloc[:,-1] \n",
    " \n",
    "    # Checking missing values in dataset\n",
    "    #print((np.sum(heart_X.isnull(),axis=0)))\n",
    "\n",
    "    # Dropping columns with missing values more than 20\n",
    "    heart_X.dropna(axis=1,thresh=heart_X.shape[0] - 20,inplace=True)\n",
    "\n",
    "    # Imputing missing values in numerical columns\n",
    "    num_imputer=SimpleImputer(strategy=\"mean\")\n",
    "    heart_X.loc[:,heart_X.dtypes == \"float64\"] = num_imputer.fit_transform(heart_X.loc[:,heart_X.dtypes == \"float64\"])\n",
    "\n",
    "    # Imputing missing values in categorical columns\n",
    "    #cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    #heart_X.loc[:,heart_X.dtypes == \"object\"] = cat_imputer.fit_transform(heart_X.loc[:,heart_X.dtypes == \"object\"])\n",
    "\n",
    "    # converting categorival variables to numerical variables\n",
    "    column_names=heart_X.loc[:,heart_X.dtypes == \"object\"].columns\n",
    "   \n",
    "    heart_X = category_to_number(heart_X,to_ordinal=column_names)    \n",
    "    \n",
    "    # Feature Scaling\n",
    "    \n",
    "    Scaler_2 = MinMaxScaler(feature_range=(0, 1)).fit(heart_X)\n",
    "    heart_X = pd.DataFrame(Scaler_2.transform(heart_X)) \n",
    "    \n",
    "    # Feature Selection\n",
    "     \n",
    "    cols = Feature_selection(heart_X,heart_y)\n",
    "    heart_X = heart_X.iloc[:,cols]\n",
    "    \n",
    "    return heart_X, heart_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d580bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the cross-validation procedure With Over and under sampling confgured\n",
    "def Cross_Validation(X,y,ToDoOversample = 0, ToDoUnderSample = 0,datasetName=''):\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        from imblearn.under_sampling import RandomUnderSampler\n",
    "        cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        # enumerate splits\n",
    "        outer_results = list()\n",
    "\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        CrossValResults = [] \n",
    "        for train_index, test_index in cv_outer.split(X):\n",
    "            # split data\n",
    "            X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            # configure the cross-validation procedure\n",
    "            cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "            # define search space\n",
    "            Dataset = []  \n",
    "            ModelNames = []\n",
    "            for name,params,model in models:        \n",
    "                # define search\n",
    "                #print('InsideLoop')\n",
    "                search = GridSearchCV(model, params, scoring='accuracy', cv=cv_inner, refit=True)\n",
    "                if ToDoOversample == 1:\n",
    "                    #print('InsideLoop1')\n",
    "                    # SMOTE OVER SAMPLING\n",
    "                    sm = SMOTE()\n",
    "                    X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "                    X_train = X_train_oversampled\n",
    "                    y_train = y_train_oversampled\n",
    "\n",
    "                if ToDoUnderSample ==1:  \n",
    "                    #print('InsideLoop2')\n",
    "                    # Random Under Sampling\n",
    "                    rus = RandomUnderSampler(sampling_strategy=\"not minority\")\n",
    "                    X_train_undersampled, y_train_undersampled = rus.fit_resample(X_train, y_train)\n",
    "                    X_train = X_train_undersampled\n",
    "                    y_train = y_train_undersampled\n",
    "\n",
    "                # execute search\n",
    "                #print('Execute Search')\n",
    "                result = search.fit(X_train, y_train)\n",
    "                # get the best performing model fit on the whole training set\n",
    "                best_model = result.best_estimator_\n",
    "                # evaluate model on the hold out dataset\n",
    "                Ypr = best_model.predict(X_test)\n",
    "                # evaluate the model\n",
    "                acc = accuracy_score(y_test, Ypr)\n",
    "                # store the result\n",
    "                outer_results.append(acc)\n",
    "                # report progress\n",
    "                # print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "                ModelNames.append(name)\n",
    "                CrossValResults.append(acc)\n",
    "                Dataset.append(datasetName)\n",
    "        # summarize the estimated performance of the model\n",
    "        # print('Accuracy: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
    "\n",
    "        #print('Before For Loop')\n",
    "        for i in range(len(ModelNames)):\n",
    "            print(ModelNames[i],CrossValResults[i].mean() , Dataset[i])\n",
    "\n",
    "        return ModelNames,CrossValResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c094f8",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning for the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9727d37",
   "metadata": {},
   "source": [
    "### K Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c85604cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "kfold_validation=  KFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a06ae",
   "metadata": {},
   "source": [
    "### Hyper parameter Tuning Configurations Parameters for 6 Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "92024953",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y  = get_dataset()\n",
    "Labor_X,Labor_y = Get_Labordataset()\n",
    "Heart_X,Heart_y = Get_HeartDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd73b31",
   "metadata": {},
   "source": [
    "### Drug data Set - Cross Validation - Experiment A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9f89ff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before For Loop\n",
      "SVM 0.8941798941798942 Drug Dataset CV\n",
      "DT 0.8941798941798942 Drug Dataset CV\n",
      "RF 0.8835978835978836 Drug Dataset CV\n",
      "KNN 0.8941798941798942 Drug Dataset CV\n"
     ]
    }
   ],
   "source": [
    "DrugDS_CV_Scores = [] \n",
    "DrugDS_CV_Scores = Cross_Validation(X,y,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d44bce3",
   "metadata": {},
   "source": [
    "### Drug data Set - Over Sampling - Experiment B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ee2252a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before For Loop\n",
      "SVM 0.7301587301587301 Drug Dataset CV\n",
      "DT 0.7883597883597884 Drug Dataset CV\n",
      "RF 0.8677248677248677 Drug Dataset CV\n",
      "KNN 0.7724867724867724 Drug Dataset CV\n"
     ]
    }
   ],
   "source": [
    "DrugDS_OvrSample_Scores = []\n",
    "DrugDS_OvrSample_Scores   = Cross_Validation(X,y,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b83b1",
   "metadata": {},
   "source": [
    "### Drug data Set - Under Sampling - Experiment C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "eb14b22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before For Loop\n",
      "SVM 0.656084656084656 Drug Dataset CV\n",
      "DT 0.7513227513227513 Drug Dataset CV\n",
      "RF 0.7354497354497355 Drug Dataset CV\n",
      "KNN 0.6613756613756614 Drug Dataset CV\n"
     ]
    }
   ],
   "source": [
    "DrugDS_UnderSample_Scores = []\n",
    "DrugDS_UnderSample_Scores = Cross_Validation(X,y,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e3365",
   "metadata": {},
   "source": [
    "#### Labor Relations Data set - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "244dcdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before For Loop\n",
      "SVM 0.8333333333333334 Drug Dataset CV\n",
      "DT 0.8333333333333334 Drug Dataset CV\n",
      "RF 0.8333333333333334 Drug Dataset CV\n",
      "KNN 0.8333333333333334 Drug Dataset CV\n"
     ]
    }
   ],
   "source": [
    "Labor_CV_Scores = [] \n",
    "Labor_CV_Scores = Cross_Validation(Labor_X,Labor_y,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d9f10",
   "metadata": {},
   "source": [
    "#### Labor Data set - Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c42632f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before For Loop\n",
      "SVM 0.8333333333333334 Drug Dataset CV\n",
      "DT 0.8333333333333334 Drug Dataset CV\n",
      "RF 0.8333333333333334 Drug Dataset CV\n",
      "KNN 0.5 Drug Dataset CV\n"
     ]
    }
   ],
   "source": [
    "LaborDS_OvrSample_Scores = []\n",
    "LaborDS_OvrSample_Scores = Cross_Validation(Labor_X,Labor_y,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "074fb4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM DT RF\n"
     ]
    }
   ],
   "source": [
    "print(LaborDS_OvrSample_Scores[0][0],LaborDS_OvrSample_Scores[0][1],LaborDS_OvrSample_Scores[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7472e8",
   "metadata": {},
   "source": [
    "#### Labor Data set - Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d7f71155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before For Loop\n",
      "SVM 1.0 Drug Dataset CV\n",
      "DT 1.0 Drug Dataset CV\n",
      "RF 1.0 Drug Dataset CV\n",
      "KNN 0.8333333333333334 Drug Dataset CV\n"
     ]
    }
   ],
   "source": [
    "LaborDS_UnderSample_Scores = []\n",
    "LaborDS_UnderSample_Scores = Cross_Validation(Labor_X,Labor_y,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b234b30",
   "metadata": {},
   "source": [
    "#### Heart Disease Data set - CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "225f9c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before For Loop\n",
      "SVM 0.7666666666666667 Drug Dataset CV\n",
      "DT 0.7333333333333333 Drug Dataset CV\n",
      "RF 0.7333333333333333 Drug Dataset CV\n",
      "KNN 0.7 Drug Dataset CV\n"
     ]
    }
   ],
   "source": [
    "Heart_CV_Scores = []\n",
    "Heart_CV_Scores = Cross_Validation(Heart_X,Heart_y,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d36c05",
   "metadata": {},
   "source": [
    "#### Heart Disease Data set - Over Sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a9334d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before For Loop\n",
      "SVM 0.7 Drug Dataset CV\n",
      "DT 0.7333333333333333 Drug Dataset CV\n",
      "RF 0.7666666666666667 Drug Dataset CV\n",
      "KNN 0.7333333333333333 Drug Dataset CV\n"
     ]
    }
   ],
   "source": [
    "Heart_OvrSample_Scores = []\n",
    "Heart_OvrSample_Scores = Cross_Validation(Heart_X,Heart_y,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452c171",
   "metadata": {},
   "source": [
    "#### Heart Disease Data set - Under Sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ef080264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before For Loop\n",
      "SVM 0.7333333333333333 Drug Dataset CV\n",
      "DT 0.6666666666666666 Drug Dataset CV\n",
      "RF 0.7666666666666667 Drug Dataset CV\n",
      "KNN 0.7333333333333333 Drug Dataset CV\n"
     ]
    }
   ],
   "source": [
    "Heart_UnderSample_Scores = []\n",
    "Heart_UnderSample_Scores = Cross_Validation(Heart_X,Heart_y,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c10dd0",
   "metadata": {},
   "source": [
    "#### Table showing Average of Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64c33b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating index for the Table\n",
    "Datasets = [\"Drug Dataset\",\"Drug Dataset - OS\",\"Drug Dataset - US\" ,\"Labor CV DS\", \"Heart CV DS\"]\n",
    "\n",
    "Algorithms =[\"SVM\", \"DT\", \"RF\", \"KNN\" , \"MLP\" , \"GB\"]\n",
    "pairs = ((key,value)  for key in Datasets for value in Algorithms)\n",
    "Multi_columns=pd.MultiIndex.from_tuples([*pairs])\n",
    "\n",
    "# Merging results and obtaing data\n",
    "Kflod_data =np.c_[[DrugDS_CV_Scores[0][1],\n",
    "                  DrugDS_CV_Scores[1][1],\n",
    "                  DrugDS_CV_Scores[2][1],\n",
    "                  DrugDS_CV_Scores[3][1],\n",
    "                  DrugDS_CV_Scores[4][1],\n",
    "                  DrugDS_CV_Scores[5][1],\n",
    "                   \n",
    "                   \n",
    "                  DrugDS_OvrSample_Scores[0][1],\n",
    "                  DrugDS_OvrSample_Scores[1][1],\n",
    "                  DrugDS_OvrSample_Scores[2][1],\n",
    "                  DrugDS_OvrSample_Scores[3][1],\n",
    "                  DrugDS_OvrSample_Scores[4][1],\n",
    "                  DrugDS_OvrSample_Scores[5][1],\n",
    "                  \n",
    "                  DrugDS_UnderSample_Scores[0][1],\n",
    "                  DrugDS_UnderSample_Scores[1][1],\n",
    "                  DrugDS_UnderSample_Scores[2][1],\n",
    "                  DrugDS_UnderSample_Scores[3][1], \n",
    "                  DrugDS_UnderSample_Scores[4][1],\n",
    "                  DrugDS_UnderSample_Scores[5][1],\n",
    "                   \n",
    "                  Labor_CV_Scores[0][1],\n",
    "                  Labor_CV_Scores[1][1],\n",
    "                  Labor_CV_Scores[2][1],\n",
    "                  Labor_CV_Scores[3][1], \n",
    "                  Labor_CV_Scores[4][1],  \n",
    "                  Labor_CV_Scores[5][1],  \n",
    "              \n",
    "                  \n",
    "                  Heart_CV_Scores[0][1],\n",
    "                  Heart_CV_Scores[1][1],\n",
    "                  Heart_CV_Scores[2][1],\n",
    "                  Heart_CV_Scores[3][1],\n",
    "                  Heart_CV_Scores[4][1],\n",
    "                  Heart_CV_Scores[5][1]]\n",
    "                  ]\n",
    "\n",
    "Kflod_data\n",
    "# Creating final table\n",
    " \n",
    "DataSet_Algorithms_AccuracyTable = pd.DataFrame(data=Kflod_data.reshape((5,6)),columns=Algorithms,index = Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "452c03d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>KNN</th>\n",
       "      <th>MLP</th>\n",
       "      <th>GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drug Dataset</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug Dataset - OS</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug Dataset - US</th>\n",
       "      <td>0.656</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labor CV DS</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart CV DS</th>\n",
       "      <td>0.766</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SVM     DT      RF    KNN    MLP     GB\n",
       "Drug Dataset       0.894  0.894   0.884  0.894  0.894  0.894\n",
       "Drug Dataset - OS   0.73  0.788  0.8677  0.772  0.772  0.894\n",
       "Drug Dataset - US  0.656  0.751   0.735  0.661  0.719  0.894\n",
       "Labor CV DS        0.833  0.833   0.833  0.833  0.833  0.833\n",
       "Heart CV DS        0.766  0.733   0.733    0.7  0.833  0.833"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet_Algorithms_AccuracyTable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14053ef",
   "metadata": {},
   "source": [
    "## Labor dataset\n",
    "The Labor and Heart data set was subjected to OVer sampling and Under sampling.\n",
    "The Labor Data set is having better accuracies with just cross validation. Under sampling has significantly overfitted the data\n",
    "And with labor data set the Over sampling  has similar accuracies as normal cross validation which is not quite significant.\n",
    "## Heart dataset\n",
    "Heart dataset is subjected to cross validation, under and over sampling. \n",
    "The heart dataset accuracy was reduced for Decision tree with under sampling and other models performed better with under sampling\n",
    "The heart dataset does not have significant performance improvement with Under or over sampling. So we retain the Heart data set with just cross validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db2d14",
   "metadata": {},
   "source": [
    "#### Statistical significant differences between the results using Friedman’s test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44a4da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FncFriedmanTest(Dataset,names):\n",
    "    \n",
    "    n,k=Dataset.shape\n",
    "    \n",
    "    Rank_table = Dataset.rank(axis=1,method=\"max\",ascending=False)\n",
    "    avg_ranks=np.mean(Rank_table,axis=0)\n",
    "    \n",
    "    R_d = sum((avg_ranks*n))/(n*k)\n",
    "    ssd1 = n * sum((avg_ranks - R_d)**2)\n",
    "    ssd2 = sum(np.sum((Rank_table-R_d)**2).values)/(n*(k-1))\n",
    "    \n",
    "    F_stat = ssd1/ssd2 \n",
    "    \n",
    "    return F_stat,avg_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "217216d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FriedmanStatistic_value,rankAvg = FncFriedmanTest(Dataset= DataSet_Algorithms_AccuracyTable  ,names=Algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44e917c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Friedman's Statistic p value obtained: 5.581728799672265\n",
      "The Average ranks from Friedman's Test:\n",
      "\n",
      "SVM    5.2\n",
      "DT     4.2\n",
      "RF     4.4\n",
      "KNN    5.4\n",
      "MLP    4.4\n",
      "GB     3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"The Friedman's Statistic p value obtained: {}\".format(FriedmanStatistic_value))\n",
    "\n",
    "print(\"The Average ranks from Friedman's Test:\\n\")\n",
    "print(rankAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f6155",
   "metadata": {},
   "source": [
    "The critical value for k = 6 (Algorithms) and n = 5 (Datasets) at the α = 0.05 has a critical value = 12.592\n",
    "\n",
    "The null hypothesis being all the algorithms are performally equally.\n",
    "With the Friedmans statistic value being 5.58 we accept the Null Hypothesis.\n",
    "And all algorithms are performing equally "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219eb05",
   "metadata": {},
   "source": [
    "#### Calculating Critical difference using Nemenyi post-hoc pairwise test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c1d699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Orange\n",
    "#!pip3 install Orange3-Associate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a833b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Critical difference value 3.3718 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Orange \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from Orange.evaluation import compute_CD\n",
    "\n",
    "# Calculating Critical difference\n",
    "Critical_difference = compute_CD(rankAvg.values,n=5) # n = 5   , number of Datasets\n",
    "print(\"\\n Critical difference value {:.4f} \\n\".format(Critical_difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb32d992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x175 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drawing the Neimanyi Diagram\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from Orange.evaluation import graph_ranks\n",
    "\n",
    "values = rankAvg.values\n",
    "methods = rankAvg.index\n",
    "graph_ranks(values,methods,cd=Critical_difference,width = 5,textspace = 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
